image:
  # -- The repository to pull the image from.
  repository: sissbruecker/linkding
  # -- The docker tag, if left empty chart's appVersion will be used.
  tag: 1.15.1
  # -- The pull policy for the deployment.
  pullPolicy: IfNotPresent

nameOverride: ''
fullnameOverride: ''

deployment:
  # -- Create a workload for this chart.
  enabled: true
  # -- Type of the workload object.
  kind: Deployment
  # -- The number of replicas.
  replicas: 1
  # -- Additional annotations for the deployment object.
  annotations: {}
  # -- Additional labels for the deployment object.
  labels: {}

service:
  # -- Create a service for exposing this chart.
  enabled: true
  # -- The service type used.
  type: ClusterIP
  # -- Additional annotations for the service object.
  annotations: {}
  # -- Additional labels for the service object.
  labels: {}

ingressRoute:
  # -- Create an IngressRoute object for exposing this chart.
  create: false
  # -- List of [entry points](https://doc.traefik.io/traefik/routing/routers/#entrypoints) on which the ingress route will be available.
  entryPoints: []
  # -- [Matching rule](https://doc.traefik.io/traefik/routing/routers/#rule) for the underlying router.
  rule: ''
  # -- List of [middleware objects](https://doc.traefik.io/traefik/routing/providers/kubernetes-crd/#kind-middleware) for the ingress route.
  middlewares: []
  # -- Use an existing secret containing the TLS certificate.
  tlsSecretName: ''
  # -- Additional annotations for the ingress route object.
  annotations: {}
  # -- Additional labels for the ingress route object.
  labels: {}

certificate:
  # -- Create an Certificate object for the exposed chart.
  create: false
  # -- List of subject alternative names for the certificate.
  dnsNames: []
  # -- Name of the secret in which the certificate will be stored. Defaults to the first item in dnsNames.
  secretName: ''
  issuerRef:
    # -- Type of the referenced certificate issuer. Can be "Issuer" or "ClusterIssuer".
    kind: ClusterIssuer
    # -- Name of the referenced certificate issuer.
    name: ''
  # -- Additional annotations for the certificate object.
  annotations: {}
  # -- Additional labels for the certificate object.
  labels: {}

env:
  # -- Timezone for the container.
  - name: TZ
    value: UTC

ports:
  http:
    # -- Enable the port inside the `Deployment` and `Service` objects.
    enabled: true
    # -- The port used as internal port and cluster-wide port if `.service.type` == `ClusterIP`.
    port: 9090
    # -- The external port used if `.service.type` == `NodePort`.
    nodePort: null
    # -- The protocol used for the service.
    protocol: TCP

persistentVolumeClaim:
  # -- Create a new persistent volume claim object.
  create: true
  # -- Mount path of the persistent volume claim object.
  mountPath: /etc/linkding/data
  # -- Storage class name for the persistent volume claim object.
  storageClassName: ''
  # -- Use an existing persistent volume claim object.
  existingPersistentVolumeClaim: ''
  # -- Additional annotations for the persistent volume claim object.
  annotations: {}
  # -- Additional labels for the persistent volume claim object.
  labels: {}

serviceAccount:
  # -- Specify the service account used for the deployment.
  name: ''

# -- Specify any additional containers here as dictionary items - each should have it's own key.
additionalContainers: {}
  # container:
  #   name: my-container
  #   image: my-org/my-image

# -- Pod-level security attributes. More info [here](https://kubernetes.io/docs/reference/kubernetes-api/workload-resources/pod-v1/#security-context).
securityContext: {}
  # fsGroup: 1000
  # runAsNonRoot: true
  # runAsGroup: 1000
  # runAsUser: 1000

# -- Compute resources used by the container. More info [here](https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/).
resources: {}
  # limits:
  #   cpu: 100m
  #   memory: 128Mi
  # requests:
  #   cpu: 100m
  #   memory: 128Mi

# -- Pod-level affinity. More info [here](https://kubernetes.io/docs/reference/kubernetes-api/workload-resources/pod-v1/#scheduling).
affinity: {}
  # nodeAffinity:
  #   requiredDuringSchedulingIgnoredDuringExecution:
  #     nodeSelectorTerms:
  #       - matchExpressions:
  #           - key: kubernetes.io/hostname
  #             operator: In
  #             values:
  #               - my-node-xyz

# -- Pod-level tolerations. More info [here](https://kubernetes.io/docs/reference/kubernetes-api/workload-resources/pod-v1/#scheduling).
tolerations: {}
  # - key: node-role.kubernetes.io/control-plane
  #   operator: Exists
  #   effect: NoSchedule
